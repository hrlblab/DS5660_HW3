{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer Learning In PyTorch\n",
    "The goal of this assignment is to implement pretrained models in Pytorch to perform classification and test it out on the given data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the begining, please import all the package you need. We provide some packages here, which might be helpful when you build your code."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "#from torchvision.models import MobileNet_V3_Large_Weights\n",
    "#from torchvision.models import MobileNet_V3_Small_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task: Use MobileNet V3 for the mini cifar-10 data\n",
    "However, the images we've used in CIFAR-10 are easy and the image sizes are small. If we need to do a more complicated classification task with high-resolution images, we may use a more deep network model. Here, we will use the pretrain MobileNet v3 large model for the mini cifar-10 data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#traindir = f\"data/cifar-10-batches-py/train\"\n",
    "#validdir = f\"data/cifar-10-batches-py/val\"\n",
    "traindir = f\"data/cifar-10-mini/train\"\n",
    "validdir = f\"data/cifar-10-mini/val\"\n",
    "\n",
    "#save_file_name = f'mobilenetv3-transfer.pt'\n",
    "#checkpoint_path = f'mobilenetv3-transfer.pth'\n",
    "\n",
    "# Change to fit hardware\n",
    "batch_size = 8\n",
    "batch_size"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For deep learning, data augmentation is significant for increasing the dataset and improving the performance. We will define crop, rotation, color jitter, and flip before we load images in our network."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define transforms\n",
    "# Image transformations\n",
    "image_transforms = {\n",
    "    # Train uses data augmentation\n",
    "    'train':\n",
    "        transforms.Compose([\n",
    "            # You can use transforms.RandomResizedCrop() for crop\n",
    "            # You can use transforms.RandomRotation() for rotation\n",
    "            # You can use transforms.ColorJitter() for colorjitter\n",
    "            # You can use transforms.RandomHorizontalFlip() for flip\n",
    "            #####################\n",
    "            ### YOUR CODE HERE###\n",
    "            #####################\n",
    "            transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            ####################\n",
    "            ### YOUR CODE END###\n",
    "            ####################\n",
    "            transforms.CenterCrop(size=224),  # Image net standards\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "        ]),\n",
    "    # Validation does not use augmentation\n",
    "    'valid':\n",
    "        transforms.Compose([\n",
    "            transforms.Resize(size=256),\n",
    "            transforms.CenterCrop(size=224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now for each original image, we can obtain several processed images. Now we can load the grocery data here. Since we load all the images from folders, and we need to extract the labels from folder names, the dataloader might be different. Then, we can check all the classes in our new dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Datasets from folders\n",
    "\n",
    "data = {\n",
    "    'train':\n",
    "    datasets.ImageFolder(root=traindir, transform=image_transforms['train']),\n",
    "    'valid':\n",
    "    #####################\n",
    "    ### YOUR CODE HERE###\n",
    "    #####################\n",
    "    datasets.ImageFolder(root=validdir, transform=image_transforms['valid'])\n",
    "    ####################\n",
    "    ### YOUR CODE END###\n",
    "    ####################\n",
    "}\n",
    "\n",
    "# Dataloader iterators, make sure to shuffle\n",
    "# You can use the same dataloader in HW3\n",
    "#####################\n",
    "### YOUR CODE HERE###\n",
    "#####################\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(data['train'], batch_size=batch_size, shuffle=True,num_workers=10),\n",
    "    'val': torch.utils.data.DataLoader(data['valid'], batch_size=batch_size, shuffle=True,num_workers=10)\n",
    "}\n",
    "####################\n",
    "### YOUR CODE END###\n",
    "####################\n",
    "\n",
    "# Iterate through the dataloader once\n",
    "trainiter = iter(dataloaders['train'])\n",
    "validationiter = iter(dataloaders['val'])\n",
    "\n",
    "categories = []\n",
    "for d in os.listdir(traindir):\n",
    "    categories.append(d)\n",
    "\n",
    "n_classes = len(categories)\n",
    "n_classes\n",
    "#print(f'There are {n_classes} different classes.')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's take a look at the data augmentation we've defined. After the data augmentation, the image values might be out of the range. Therefore, when we print the images, we may clip the value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# take a look at data augmentation\n",
    "\n",
    "def imshow_tensor(image, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "\n",
    "    # Set the color channel as the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    # Reverse the preprocessing steps\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "\n",
    "    # Clip the image pixel values\n",
    "    # You may use np.clip() to clip the value between 0 to 1.\n",
    "    #####################\n",
    "    ### YOUR CODE HERE###\n",
    "    #####################\n",
    "    image = np.clip(image, 0, 1)\n",
    "    ####################\n",
    "    ### YOUR CODE END###\n",
    "    ####################\n",
    "    plt.figure(figsize=(24, 24))\n",
    "\n",
    "    plt.imshow(image)\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "imshow_tensor(out, title = [data['train'].classes[x] for x in classes])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we may define our model with the pretrianed mobilenet v3 large. For the pretrained model, the output channels might match the original dataset. Therefore, we need to change the last block of network specially for our dataset. Because we use pretrain model, we may freeze all the layers that related to the features learning. Then, our model can only learn the feature classifier with the last block we've defined."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the network with pretrained models.mobilenet_v3_large\n",
    "\n",
    "model = models.mobilenet_v3_large(weights = models.MobileNet_V3_Large_Weight.IMAGENET1K_V1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# print(model)\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "\n",
    "                      nn.Linear(in_features=960, out_features=1280, bias=True),\n",
    "                      nn.Hardswish(),\n",
    "                      nn.Dropout(p=0.2, inplace=True),\n",
    "                      nn.Linear(in_features=1280, out_features=n_classes, bias=True)\n",
    "\n",
    "\n",
    "                      #nn.Linear(in_features=576, out_features=1024, bias=True),\n",
    "                      #nn.Hardswish(),\n",
    "                      #nn.Dropout(p=0.2, inplace=True),\n",
    "                      #nn.Linear(in_features=1024, out_features=n_classes, bias=True)\n",
    "\n",
    "                      )\n",
    "#model.classifier\n",
    "#model\n",
    "\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can set up the hyper parameters for our network."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.class_to_idx = data['train'].class_to_idx\n",
    "model.idx_to_class = {\n",
    "    idx: class_\n",
    "    for class_, idx in model.class_to_idx.items()\n",
    "}\n",
    "\n",
    "list(model.idx_to_class.items())\n",
    "\n",
    "\n",
    "# Set up your criterion and optimizer\n",
    "# You can use nn.CrossEntropyLoss() as your critenrion\n",
    "# You can use optim.Adam() as your optimizer with reasonable momentum\n",
    "\n",
    "#####################\n",
    "### YOUR CODE HERE###\n",
    "#####################\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "####################\n",
    "### YOUR CODE END###\n",
    "####################\n",
    "\n",
    "for p in optimizer.param_groups[0]['params']:\n",
    "    if p.requires_grad:\n",
    "        print(p.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Well down! Now we can start our training process here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          train_loader,\n",
    "          valid_loader,\n",
    "          save_file_name,\n",
    "          max_epochs_stop=3,\n",
    "          n_epochs=10,\n",
    "          print_every=1):\n",
    "    \"\"\"Train a PyTorch Model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): model to train\n",
    "        criterion (PyTorch loss): objective to minimize\n",
    "        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n",
    "        train_loader (PyTorch dataloader): training dataloader to iterate through\n",
    "        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n",
    "        save_file_name (str ending in '.pt'): file path to save the model state dict\n",
    "        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n",
    "        n_epochs (int): maximum number of training epochs\n",
    "        print_every (int): frequency of epochs to print training stats\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        model (PyTorch model): trained cnn with best weights\n",
    "        history (DataFrame): history of train and validation loss and accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Early stopping intialization\n",
    "    epochs_no_improve = 0\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    valid_max_acc = 0\n",
    "    history = []\n",
    "\n",
    "    # Number of epochs already trained (if using loaded in model weights)\n",
    "    try:\n",
    "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
    "    except:\n",
    "        model.epochs = 0\n",
    "        print(f'Starting Training from Scratch.\\n')\n",
    "\n",
    "    overall_start = timer()\n",
    "\n",
    "    # Main loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # keep track of training and validation loss each epoch\n",
    "\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_acc = 0\n",
    "        valid_acc = 0\n",
    "\n",
    "\n",
    "        # Set to training\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        start = timer()\n",
    "\n",
    "        # Training loop\n",
    "        for ii, (data, target) in enumerate(train_loader):\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get your output from your model\n",
    "\n",
    "            model = model.float()\n",
    "            output = model(data.float())\n",
    "\n",
    "            # Loss and backpropagation of gradients\n",
    "\n",
    "            loss = criterion(output, target.long())\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            #####################\n",
    "            ### YOUR CODE HERE###\n",
    "            #####################\n",
    "            optimizer.step()\n",
    "            #####################\n",
    "            ### YOUR CODE END ###\n",
    "            #####################\n",
    "\n",
    "            # Track train loss by multiplying average loss by number of examples in batch\n",
    "\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "\n",
    "\n",
    "            # Calculate accuracy by finding max log probability\n",
    "\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "\n",
    "\n",
    "            # Need to convert correct tensor from int to float to average\n",
    "\n",
    "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "\n",
    "\n",
    "            # Multiply average accuracy times the number of examples in batch\n",
    "\n",
    "            train_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "\n",
    "            # Track training progress\n",
    "            print(\n",
    "                f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
    "                end='\\r')\n",
    "\n",
    "        # After training loops ends, start validation\n",
    "        else:\n",
    "            model.epochs += 1\n",
    "\n",
    "            # Don't need to keep track of gradients\n",
    "            with torch.no_grad():\n",
    "\n",
    "                # Set to evaluation mode\n",
    "\n",
    "                model.eval()\n",
    "\n",
    "\n",
    "                # Validation loop\n",
    "                for data, target in valid_loader:\n",
    "\n",
    "\n",
    "\n",
    "                    # Forward pass\n",
    "\n",
    "                    model = model.float()\n",
    "                    output = model(data.float())\n",
    "\n",
    "\n",
    "                    # Validation loss\n",
    "\n",
    "                    loss = criterion(output, target.long())\n",
    "\n",
    "\n",
    "\n",
    "                    # Multiply average loss times the number of examples in batch\n",
    "\n",
    "                    valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "\n",
    "                    # Calculate validation accuracy\n",
    "\n",
    "                    _, pred = torch.max(output, dim=1)\n",
    "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                    accuracy = torch.mean(\n",
    "                        correct_tensor.type(torch.FloatTensor))\n",
    "\n",
    "\n",
    "                    # Multiply average accuracy times the number of examples\n",
    "\n",
    "                    valid_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "\n",
    "                # Calculate average losses\n",
    "\n",
    "                train_loss = train_loss / len(train_loader.dataset)\n",
    "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "\n",
    "                # Calculate average accuracy\n",
    "\n",
    "                train_acc = train_acc / len(train_loader.dataset)\n",
    "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
    "\n",
    "\n",
    "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
    "\n",
    "                # Print training and validation results\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\n",
    "                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
    "                    )\n",
    "                    print(\n",
    "                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
    "                    )\n",
    "\n",
    "                # Save the model if validation loss decreases\n",
    "                if valid_loss < valid_loss_min:\n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), save_file_name)\n",
    "                    # Track improvement\n",
    "                    epochs_no_improve = 0\n",
    "                    valid_loss_min = valid_loss\n",
    "                    valid_best_acc = valid_acc\n",
    "                    best_epoch = epoch\n",
    "\n",
    "                # Otherwise increment count of epochs with no improvement\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    # Trigger early stopping\n",
    "                    if epochs_no_improve >= max_epochs_stop:\n",
    "                        print(\n",
    "                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "                        )\n",
    "                        total_time = timer() - overall_start\n",
    "                        print(\n",
    "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
    "                        )\n",
    "\n",
    "                        # Load the best state dict\n",
    "\n",
    "                        model.load_state_dict(torch.load(save_file_name))\n",
    "\n",
    "                        # Attach the optimizer\n",
    "                        model.optimizer = optimizer\n",
    "\n",
    "                        # Format history\n",
    "                        history = pd.DataFrame(\n",
    "                            history,\n",
    "                            columns=[\n",
    "                                'train_loss', 'valid_loss', 'train_acc',\n",
    "                                'valid_acc'\n",
    "                            ])\n",
    "                        return model, history\n",
    "\n",
    "    # Attach the optimizer\n",
    "    model.optimizer = optimizer\n",
    "    # Record overall time and print out stats\n",
    "    total_time = timer() - overall_start\n",
    "    print(\n",
    "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_best_acc:.2f}%'\n",
    "    )\n",
    "    print(\n",
    "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
    "    )\n",
    "    # Format history\n",
    "    history = pd.DataFrame(\n",
    "        history,\n",
    "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
    "    return model, history"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "save_file_name = f'mobilenet_v3_model_best_model.pt'\n",
    "\n",
    "\n",
    "model, history = train(model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    dataloaders['train'],\n",
    "    dataloaders['val'],\n",
    "    save_file_name=save_file_name,\n",
    "    max_epochs_stop=3,\n",
    "    n_epochs=5,\n",
    "    print_every=1)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_loss', 'valid_loss']:\n",
    "    plt.plot(\n",
    "        history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Negative Log Likelihood')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_acc', 'valid_acc']:\n",
    "    plt.plot(\n",
    "        100 * history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    npimg = npimg.transpose(1,2,0)\n",
    "\n",
    "    plt.imshow(npimg)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataiter = iter(validationiter)\n",
    "# get some random training images\n",
    "# you may use .next() to get the next iteration of validation dataloader\n",
    "######################\n",
    "### YOUR CODE HERE ###\n",
    "######################\n",
    "images, labels = dataiter.__next__()\n",
    "#####################\n",
    "### YOUR CODE END ###\n",
    "#####################\n",
    "\n",
    "# Get the prediction of images by using your model.\n",
    "#####################\n",
    "### YOUR CODE HERE###\n",
    "#####################\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "#predicted\n",
    "####################\n",
    "### YOUR CODE END###\n",
    "####################\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % categories[labels[j].long()] for j in range(batch_size)))\n",
    "print('Prediction: ', ' '.join('%5s' % categories[predicted[j].long()] for j in range(batch_size)))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
